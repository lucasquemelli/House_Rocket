{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df658999",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a798a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df83b2a2",
   "metadata": {},
   "source": [
    "# 1.0. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b94e9ea0",
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 11001] getaddrinfo failed>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1345\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1346\u001b[1;33m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[0;32m   1347\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1256\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1257\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1302\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1303\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1251\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1252\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1011\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1012\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1013\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    953\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1419\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    922\u001b[0m         \u001b[1;34m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 923\u001b[1;33m         self.sock = self._create_connection(\n\u001b[0m\u001b[0;32m    924\u001b[0m             (self.host,self.port), self.timeout, self.source_address)\n",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSOCK_STREAM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    952\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 953\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    954\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\USURIO~3\\AppData\\Local\\Temp/ipykernel_12352/2658863954.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Dataset upload from URL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://raw.githubusercontent.com/lucasquemelli/House_Rocket/main/kc_house_data.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m     \u001b[1;31m# open URLs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[0;32m    609\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[1;31m# assuming storage_options is to be interpreted as headers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[0mreq_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq_info\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m             \u001b[0mcontent_encoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Content-Encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"gzip\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'urllib.Request'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 534\u001b[1;33m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[0;32m    535\u001b[0m                                   '_open', req)\n\u001b[0;32m    536\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0m\u001b[0;32m   1390\u001b[0m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0;32m   1391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\usuário\\appdata\\local\\programs\\python\\python39\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1347\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0;32m   1348\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1349\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1350\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1351\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [Errno 11001] getaddrinfo failed>"
     ]
    }
   ],
   "source": [
    "#Dataset upload from URL\n",
    "url = 'https://raw.githubusercontent.com/lucasquemelli/House_Rocket/main/kc_house_data.csv'\n",
    "data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0bdd3e",
   "metadata": {},
   "source": [
    "## 1.1. Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba8c252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization of the first 05 rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44135ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_shape(data):\n",
    "    print(\"Shape of the dataset\")\n",
    "    print(\"\\nNumber of rows: {}\\nNumber of columns: {}\".format(data.shape[0],data.shape[1]))\n",
    "    \n",
    "    return None\n",
    "\n",
    "def num_attributes(data):\n",
    "    num_attributes = len(data.columns) - 2\n",
    "    print(\"\\n\\nThe number of attribute is:\", num_attributes)\n",
    "    \n",
    "    return num_attributes\n",
    "\n",
    "def attributes(data):\n",
    "    attributes = data.drop(['id','date'], axis=1)\n",
    "    print(\"\\n\\nThe attributes are:\\n\\n\",attributes.columns.tolist())\n",
    "    \n",
    "    return attributes\n",
    "\n",
    "def data_info(data):\n",
    "    print(\"\\n\\nData types\\n\")\n",
    "    data.info()\n",
    "    \n",
    "    return None\n",
    "\n",
    "def descriptive_analysis(data):\n",
    "    pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "    print(\"\\n\\nDescriptive analysis:\\n\\n\",data.describe().T)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def display(data):\n",
    "    #Displaying unique values for the number of bedrooms, bathrooms, floors, waterfront, view, condition and grade\n",
    "    print(\"\\n\\nAttributes unique values\")\n",
    "    print(\"\\n\\nUnique values for bedrooms:\", np.sort(data['bedrooms'].unique())) \n",
    "    print(\"\\nUnique values for bathrooms:\", np.sort(data['bathrooms'].unique()))\n",
    "    print(\"\\nUnique values for floors:\", np.sort(data['floors'].unique()))\n",
    "    print(\"\\nUnique values for waterfront:\", np.sort(data['waterfront'].unique()))\n",
    "    print(\"\\nUnique values for view:\", np.sort(data['view'].unique()))\n",
    "    print(\"\\nUnique values for condition:\", np.sort(data['condition'].unique()))\n",
    "    print(\"\\nUnique values for grade:\", np.sort(data['grade'].unique()))\n",
    "\n",
    "    print(\"\\n\\nWhile there are properties with 33 bedrooms, also are there with 0. The same happens with the number of bathrooms. This would properly be classified as inconsistences, yet I choose to classify into different types of properties in this analysis.\")\n",
    "    print(\"\\n\\nThe other attributes contain a large number of unique values, such as 'id' - as it may be seen below. Thus, they were not considered in this analysis.\")\n",
    "\n",
    "    print(\"\\n\\nNumber of unique values for 'id':\", data['id'].nunique())\n",
    "    print(\"\\n\\nWhile the number of rows is 21613, the number of unique 'id' is 21436. It means there are only 21436 properties.\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    data_shape(data)\n",
    "    \n",
    "    num_attributes = num_attributes(data)\n",
    "    \n",
    "    attributes = attributes(data)\n",
    "    \n",
    "    data_info(data)\n",
    "    \n",
    "    descriptive_analysis(data)\n",
    "    \n",
    "    display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956a626f",
   "metadata": {},
   "source": [
    "**Meaning of the attributes**\n",
    "\n",
    "- ID: identification number\n",
    "- date: period in which the properties were available\n",
    "- bedrooms: number of bedrooms\n",
    "- bathrooms: number of bathrooms\n",
    "- floors: number of floors\n",
    "- waterfront: if some property has waterfront or not (0 or 1)\n",
    "- view: number of views\n",
    "- condition: condition of the properties (1 to 5)\n",
    "- grade: quality of the building and construction level\n",
    "- price: price of the property\n",
    "- sqft_living: living room built area [ft²]\n",
    "- sqft_lot: lot area [ft²]\n",
    "- sqft_above: built area above ground level [ft²]\n",
    "- sqft_basement: built basement area [ft²]\n",
    "- yr_built: year that the property was built\n",
    "- yr_renovated: year of renovation\n",
    "- sqft_living15: average built area of the 15 nearest neighboring properties [ft²]\n",
    "- sqft_lot15: average lot area of the 15 nearest neighboring properties [ft²]\n",
    "- zipcode: number of zipcode\n",
    "- lat: latitude identification number\n",
    "- long: longitude identification number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a947e13",
   "metadata": {},
   "source": [
    "## 1.2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c432f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values(data):\n",
    "    print(\"Missing values\\n\")\n",
    "    print(data.isna().sum())\n",
    "    \n",
    "    return None\n",
    "\n",
    "def ids(data):\n",
    "    ids = data['id']\n",
    "    \n",
    "    return ids\n",
    "\n",
    "def duplicates_id(data):\n",
    "    print(\"\\n\\nDuplicates\\n\")\n",
    "    print(data[ids.isin(ids[ids.duplicated()])].sort_values('id'))\n",
    "    \n",
    "    return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    missing_values(data)\n",
    "    \n",
    "    ids = ids(data)\n",
    "    \n",
    "    duplicates_id(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29e9b27",
   "metadata": {},
   "source": [
    "Duplicates (353) in this dataset are meant to be properties which were sold twice or more between 2014 and 2015. These properties were sold on different dates and at different prices. It means the price changes with time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8989e87c",
   "metadata": {},
   "source": [
    "It is important to mention that the number of duplicates is different from the number of ids that are duplicates. Notice that the same id appears twice or more. Thus, the number of ids that are duplicate is: total number of rows - number of unique ids = 177."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fd7c4d",
   "metadata": {},
   "source": [
    "## 1.3. Data Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c738a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversiong to datetime\n",
    "data['date'] =  pd.to_datetime(data['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1b488e",
   "metadata": {},
   "source": [
    "## 1.4. Outliers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b9203e",
   "metadata": {},
   "source": [
    "We may have a look at the outliers in the dataset using the boxplot chart. However, as it may be seen below, this is an univariate analysis. As the price is influenced by a lot of features in the dataset, we must remove outliers using multivariate analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf601ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y='price',data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c6009d",
   "metadata": {},
   "source": [
    "To remove outliers using multivariate analysis, we are going to use three methods: **visual method**, **Z-score method** and **interquartile range method**. Then, we are going to work *separately* with each resulting dataset and make conclusions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ea9dd9",
   "metadata": {},
   "source": [
    "Firstly, in order to use the methods **Z-score** and **interquartile range**, we have to set the column 'date' as integer as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2f9f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the feature 'date' as integer (type 1)\n",
    "df1 = data\n",
    "df1['date'] = df1['date'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f76fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the feature 'date' as integer (type 2)\n",
    "df1 = data\n",
    "df1['date'] = df1['date'].view(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eec066",
   "metadata": {},
   "source": [
    "The dataset df1 is the same in the two cases above. It was only treated with two different \"set as integer\" functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c1ad12",
   "metadata": {},
   "source": [
    "### 1.4.1. Visual method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28b26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Properties with the highest prices\n",
    "data.sort_values('price', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9e1488",
   "metadata": {},
   "source": [
    "The properties with the highest prices have such values due to their features. No anomalies were found to be considered as outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931cb404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Properties with 10 or more than 10 bedrooms\n",
    "data[data['bedrooms'] >= 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed861ac8",
   "metadata": {},
   "source": [
    "The prices of the properties above are all feasible with their features. Although perhaps the 11-bedrooms and the 33-bedrooms properties prices may be seen as anomalies, they will not be treated as outliers due to their year built (yr_built) and total area (sqft_lot). Some of their features may be atypical because of the time they were built and localization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f666e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Properties with no bedrooms\n",
    "data[data['bedrooms'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9271e338",
   "metadata": {},
   "source": [
    "Although some properties have no bedrooms, they may be treated as studios and not as apartments or even houses. They are considered like this and not as outliers due to requests from the House Rocket's CEO. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dedeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Properties with 6 or more than 6 bathrooms\n",
    "data[data['bathrooms'] >= 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799375d9",
   "metadata": {},
   "source": [
    "The prices of the properties above are all consistent with their features. Thus, they will not be treated as outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febb00de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Properties with no bathrooms\n",
    "data[data['bathrooms'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d5b8d1",
   "metadata": {},
   "source": [
    "The properties above - with no bathrooms - will be treated as outliers, since there is not a classification for them. Assuming they are a typo, these rows will be removed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec68d9c",
   "metadata": {},
   "source": [
    "#### 1.4.1.1 Dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d810d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows(data):\n",
    "    data = data.drop(data[data['bathrooms'] == 0].index)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def reset_index(data):\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def show_dimensions(data):\n",
    "    print(f\"Clean dataset: {data.shape[0]} properties (rows), {data.shape[1]} features (columns).\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    data = drop_rows(data)\n",
    "    \n",
    "    data = reset_index(data)\n",
    "    \n",
    "    show_dimensions(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3674fa",
   "metadata": {},
   "source": [
    "### 1.4.2. Z-score method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bcb42e",
   "metadata": {},
   "source": [
    "\"The Z-score is the signed number of standard deviations by which the value of an observation or data point is above the mean value of what is being observed or measured.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f35eecc",
   "metadata": {},
   "source": [
    "\"The intuition behind Z-score is to describe any data point by finding their relationship with the Standard Deviation and Mean of the group of data points. Z-score is finding the distribution of data where mean is 0 and standard deviation is 1 i.e. normal distribution.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b68ea85",
   "metadata": {},
   "source": [
    "\"Calculating the Z-score, we re-scale and center the data and look for data points which are too far from zero. These data points which are way too far from zero will be treated as the outliers.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a12846",
   "metadata": {},
   "source": [
    "In this case (project), a threshold of 3 was used. For instance, when the Z-score value was greater than 3, that data point was identified as an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3042de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardization_data(df1):\n",
    "    z1 = np.abs(stats.zscore(df1))\n",
    "    print(\"Standardized dataset:\\n\\n\", z1)\n",
    "    \n",
    "    return z1\n",
    "\n",
    "def show_index_outliers(z1):\n",
    "    #Defining threshold as 3\n",
    "    threshold = 3\n",
    "    \n",
    "    print(\"\\n\\nIndexes of the outliers:\\n\\n\",np.where(z1 > 3))\n",
    "    \n",
    "    return None\n",
    "\n",
    "def show_first_outlier(z1):\n",
    "    print(\"\\n\\nValue of the first outlier:\\n\\n\",z1.iloc[1][15])\n",
    "    \n",
    "    return None\n",
    "\n",
    "def removing_outliers(df1, z1):\n",
    "    df2 = df1[(z1 < 3).all(axis=1)]\n",
    "    \n",
    "    return df2\n",
    "\n",
    "def show_new_shape(df2):\n",
    "    print(\"\\n\\nShape of the clean dataset:\\n\\nNumber of rows:\", df2.shape[0])\n",
    "    print(\"Number of columns:\", df2.shape[1])\n",
    "    \n",
    "    return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    z1 = standardization_data(df1)\n",
    "    \n",
    "    show_index_outliers(z1)\n",
    "    \n",
    "    show_first_outlier(z1)\n",
    "    \n",
    "    df2 = removing_outliers(df1, z1)\n",
    "    \n",
    "    show_new_shape(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1766867e",
   "metadata": {},
   "source": [
    "### 1.4.3. Interquartile range (IQR) method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb4a079",
   "metadata": {},
   "source": [
    "Box plot use the IQR method to display data and outliers(shape of the data). The interquartile range (IQR) is a measure of statistical dispersion, being equal to the difference between 75th and 25th percentiles, or between upper and lower quartiles, IQR = Q3 − Q1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce20d80",
   "metadata": {},
   "source": [
    "\"It is a measure of the dispersion similar to standard deviation or variance, but is much more robust against outliers.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdfe2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quartiles(df1):\n",
    "    Q1 = df1.quantile(0.25)\n",
    "    Q3 = df1.quantile(0.75)\n",
    "    \n",
    "    return Q1, Q3\n",
    "\n",
    "def IQR_function(Q1, Q3):\n",
    "    IQR = Q3 - Q1\n",
    "    print(\"Interquartile range:\\n\\n\",IQR)\n",
    "    \n",
    "    return IQR\n",
    "\n",
    "def show_boolean_outliers(df1, Q1, Q3, IQR):\n",
    "    print(\"\\n\\nBoolean values:\\n\\n\",(df1 < (Q1 - 1.5 * IQR)) | (df1 > (Q3 + 1.5 * IQR)))\n",
    "    \n",
    "    return None\n",
    "\n",
    "def removing_outliers(df1, Q1, Q3, IQR):\n",
    "    df3 = df1[~((df1 < (Q1 - 1.5 * IQR)) | (df1 > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "    \n",
    "    return df3\n",
    "\n",
    "def show_dimensions_dataset(df3):\n",
    "    print(\"\\n\\nShape of the clean dataset:\\n\\n\",df3.shape)\n",
    "    \n",
    "    return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    Q1, Q3 = quartiles(df1)\n",
    "    \n",
    "    IQR = IQR_function(Q1, Q3)\n",
    "    \n",
    "    show_boolean_outliers(df1, Q1, Q3, IQR)\n",
    "    \n",
    "    df3 = removing_outliers(df1, Q1, Q3, IQR)\n",
    "    \n",
    "    show_dimensions_dataset(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95fe17c",
   "metadata": {},
   "source": [
    "### 1.4.4. Outliers choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077afdce",
   "metadata": {},
   "source": [
    "After tested the three methods to identify and remove outliers, I decided to choose the **visual method**. The choice was made based on number of rows which were removed, since the **Z-score and IQR methods** overexcluded the elements in the dataset without consider particular features of each property. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f363615",
   "metadata": {},
   "source": [
    "# 2.0. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3f59c5",
   "metadata": {},
   "source": [
    "## 2.1. Questions and Requests (Q&R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915cd89a",
   "metadata": {},
   "source": [
    "In order to find the most important attributes related to the price and hence improving the decision making, House Rocket's CEO created 7 sets of questions and requests. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9371ba",
   "metadata": {},
   "source": [
    "### 2.1.1. Q&R 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41f19ca",
   "metadata": {},
   "source": [
    "1. How many properties are available for purchase?\n",
    "2. How many attributes do properties have?\n",
    "3. What are the attributes of the properties?\n",
    "4. What is the most expensive property? (with the highest sale price)\n",
    "5. What property has the largest number of bedrooms?\n",
    "6. What is the total sum of the number of bedrooms in the dataset?\n",
    "7. How many properties have two bathrooms?\n",
    "8. What is the average price of all properties in the dataset?\n",
    "9. What is the average price of the properties with two bathrooms?\n",
    "10. What is the minimum price for the 3-bedrooms properties?\n",
    "11. How many properties have more than 300 square meters in the living room?\n",
    "12. How many properties have more than two floors?\n",
    "13. How many properties have a waterfront?\n",
    "14. Among properties with a waterfront, how many have three bedrooms?\n",
    "15. Among properties with more than 300 square meters in the living room, how many have more than two bathrooms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f311fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_one(data):\n",
    "    num = data['id'].nunique()\n",
    "    print(\"There are \", num,\" properties available for purchase.\")\n",
    "    \n",
    "    return num\n",
    "\n",
    "def question_two(data):\n",
    "    num_attributes = len(data.columns) - 2\n",
    "    print(\"\\n\\nThe properties have \",num_attributes,\" attributes\")\n",
    "    \n",
    "    return num_attributes\n",
    "\n",
    "def question_three(data):\n",
    "    attributes = data.drop(['id','date'],axis=1)\n",
    "    print(\"\\n\\nThe attributes are:\\n\\n\",attributes.columns.tolist())\n",
    "    \n",
    "    return attributes\n",
    "\n",
    "def question_four(data):\n",
    "    m_e_h = data[['id','price']].sort_values('price',ascending=False)\n",
    "    print(\"\\n\\nMost expensive properties:\\n\")\n",
    "    print(m_e_h)\n",
    "\n",
    "    most_expensive = data[['id','price']].sort_values('price',ascending=False).iloc[0,0]\n",
    "    print(\"\\n\\nThe most expensive property has the id:\",most_expensive)\n",
    "    \n",
    "    return m_e_h, most_expensive\n",
    "\n",
    "def question_five(data):\n",
    "    m_n_h = data[['id','bedrooms']].sort_values('bedrooms',ascending=False)\n",
    "    print(\"\\n\\nThe property with the largest number of bedrooms is in the first line:\\n\\n\",m_n_h)\n",
    "    \n",
    "    return m_n_h\n",
    "\n",
    "def question_six(data):\n",
    "    sum_bedrooms = data['bedrooms'].sum()\n",
    "    print(\"\\n\\nThe dataset total sum of bedrooms is:\",sum_bedrooms)\n",
    "    \n",
    "    return sum_bedrooms\n",
    "\n",
    "def question_seven(data):\n",
    "    dataframe = data.loc[data['bathrooms'] ==2,:]\n",
    "    number = len(dataframe)\n",
    "    print(\"\\n\\nThe number of properties with two bathrooms is:\", number)\n",
    "    \n",
    "    return dataframe\n",
    "    \n",
    "def question_eight(data):\n",
    "    average_price = np.round(data['price'].mean(),2)\n",
    "    print(\"\\n\\nThe average price of all properties is: ${}\".format(average_price))\n",
    "    \n",
    "    return average_price\n",
    "\n",
    "def question_nine(data):\n",
    "    avg_bath = np.round(data.loc[data['bathrooms']==2,'price'].mean(),2)\n",
    "    print(\"\\n\\nThe average price of the properties with 02 bathrooms is: ${}\".format(avg_bath))\n",
    "    \n",
    "    return avg_bath\n",
    "\n",
    "def question_ten(data):\n",
    "    min_price = np.round(data.loc[data['bedrooms']==3,'price'].min(),2)\n",
    "    print(\"\\n\\nThe minimum price of a 03-bedrooms property is: ${}\".format(min_price))\n",
    "    \n",
    "    return min_price\n",
    "\n",
    "def question_eleven(data):\n",
    "    more_300 = data.loc[data['sqft_living']>300,:]\n",
    "    num_ = len(more_300)\n",
    "    #print(\"\\n\\nThe number of properties with more than 300 m² is:\",num_)\n",
    "\n",
    "    num_ = data.loc[data['sqft_living']>300,:].shape[0]\n",
    "    print(\"\\n\\nThe number of properties with more than 300 m² is:\",num_)\n",
    "    \n",
    "    return more_300, num_\n",
    "\n",
    "def question_twelve(data):\n",
    "    two_floors = data.loc[data['floors']>2,:].shape[0]\n",
    "    print(\"\\n\\nThe number of properties with more than 02 floors is:\", two_floors)\n",
    "    \n",
    "    return two_floors\n",
    "\n",
    "def question_thirteen(data):\n",
    "    water_front = data.loc[data['waterfront']>0,:].shape[0]\n",
    "    print(\"\\n\\nThe number of properties with waterfront view is:\",water_front)\n",
    "    \n",
    "    return water_front\n",
    "\n",
    "def question_fourteen(data):\n",
    "    water_three = data.loc[(data['waterfront']>0) & (data['bedrooms']==3),:].shape[0]\n",
    "    print(\"\\n\\nThe number of properties with waterfront view and more than 03 bedrooms is:\",water_three)\n",
    "    \n",
    "    return water_three\n",
    "\n",
    "def question_fifteen(data):    \n",
    "    houses = data.loc[(data['sqft_living']>300) & (data['bathrooms']>2),:].shape[0]\n",
    "    print(\"\\n\\nThe number of properties with more than 300 m² and more than 02 bathrooms is:\",houses)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    num =  question_one(data)\n",
    "\n",
    "    num_attributes = question_two(data)\n",
    "\n",
    "    attributes = question_three(data)\n",
    "\n",
    "    m_e_h, most_expensive = question_four(data)\n",
    "\n",
    "    m_n_h = question_five(data)\n",
    "    \n",
    "    sum_bedrooms = question_six(data)\n",
    "\n",
    "    dataframe = question_seven(data)\n",
    "    \n",
    "    average_price = question_eight(data)\n",
    "    \n",
    "    avg_bath = question_nine(data)\n",
    " \n",
    "    min_price = question_ten(data)\n",
    "\n",
    "    num_ = question_eleven(data)\n",
    "\n",
    "    two_floors = question_twelve(data)\n",
    "\n",
    "    water_front = question_thirteen(data)\n",
    "\n",
    "    water_three = question_fourteen(data)\n",
    "  \n",
    "    houses = question_fifteen(data)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d314fc",
   "metadata": {},
   "source": [
    "### 2.1.2. Q&R 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d81c20c",
   "metadata": {},
   "source": [
    "1. What is the date of the oldest property in the portfolio?\n",
    "2. How many properties have the maximum number of floors?\n",
    "3. Create a low and high standard classification for properties:\n",
    "   - High standard: above USD 540000.00.\n",
    "   - Low standard: below USD 540000.00.\n",
    "4. Make a report (.csv file) ordered by price with the following information:\n",
    "   - Property ID;\n",
    "   - Date the property became available for purchase;\n",
    "   - Number of bedrooms;\n",
    "   - Total land size;\n",
    "   - Price;\n",
    "   - Property classification.\n",
    "5. A map where the houses are located geographically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb89d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_types(data):\n",
    "    print(\"Data types\\n\\n\",data.dtypes)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def conversion_date(data):\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    \n",
    "    return data\n",
    "\n",
    "def question_one(data):\n",
    "    min_port = data['date'].min()\n",
    "    print(\"\\n\\nThe earliest date which a property became available for purchase in the portfolio is:\",min_port)\n",
    "    \n",
    "    return min_port\n",
    "\n",
    "def question_two(data):\n",
    "    max_floors = data[data['floors'] == 3.5].shape[0]\n",
    "    print(f\"\\n\\n{max_floors} properties have the maximum number of floors.\")\n",
    "    \n",
    "    return max_floors\n",
    "\n",
    "def question_three(data):\n",
    "    data['classification'] = 'NA'\n",
    "    print(\"\\n\\nCreation of the classification column:\\n\\n\",data.columns)\n",
    "    data.loc[data['price'] > 540000, 'classification'] = \"high_standard\"\n",
    "    data.loc[data['price'] < 540000, 'classification'] = \"low_standard\"\n",
    "    print(\"\\n\\n\",data.head())\n",
    "    \n",
    "    return data\n",
    "\n",
    "def question_four(data):    \n",
    "    report = data[['id','date','bedrooms','sqft_lot','price','classification']].sort_values('price',ascending=False)\n",
    "    print(\"\\n\\nReport:\\n\\n\",report)\n",
    "    report.to_csv(\"report.csv\",index=False)\n",
    "    \n",
    "    return report\n",
    "\n",
    "#def question_five(data):\n",
    "#    data_map = data[['id','lat','long','price']]\n",
    "#    fig_map = px.scatter_mapbox(data_map, lat='lat', lon='long', hover_name='id', hover_data =['price'], zoom = 3, height = 300)\n",
    "\n",
    "#    fig_map.update_layout(mapbox_style ='open-street-map', height = 600, margin = {\"r\": 0, \"l\": 0, \"t\": 0, \"b\": 0})\n",
    "    \n",
    "#    print(\"\\n\\nMap\\n\\n\")\n",
    "\n",
    "#    fig_map.show()\n",
    "    \n",
    "#    fig_map.write_html(\"first_map.html\")\n",
    "    \n",
    "#    return data_map, fig_map\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data_types(data)\n",
    "    \n",
    "    data = conversion_date(data)\n",
    "    \n",
    "    min_port = question_one(data)\n",
    "    \n",
    "    max_floors = question_two(data)\n",
    "    \n",
    "    data = question_three(data)\n",
    "    \n",
    "    report = question_four(data)\n",
    "    \n",
    "#    data_map, fig_map = question_five(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54fdde7",
   "metadata": {},
   "source": [
    "The map made was too big to be visualized on *GitHub*. That's why the question five was marked with \"#\" to avoid its answer. Yet, the code lines are still available above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2977c91d",
   "metadata": {},
   "source": [
    "As an alternative solution, the map was deployed to Heroku: [Property map.](https://property-map-quemelli-lucas.herokuapp.com/). The script to this procedure may be found in the folders named \"Q&R => Q&R 2.0\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b5d7cb",
   "metadata": {},
   "source": [
    "### 2.1.3. Q&R 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc5f292",
   "metadata": {},
   "source": [
    "1. Create a column called: house_age. \n",
    "   - If the value of the column \"date\" is greater than 2014-01-01 => 'new_house'.\n",
    "   - If the value of the column \"date\" is less than 2014-01-01 => 'old_house'.  \n",
    "2. Create a column called: dormitory_type.\n",
    "   - If the value of the column \"bedrooms\" is equal to 1 => 'studio'.\n",
    "   - If the value of the column \"bedrooms\" is equal to 2 => 'apartment'.\n",
    "   - If the value of the column \"bedrooms\" is greater than 2 => 'house'.\n",
    "3. Create a column called: condition_type.\n",
    "   - If the value of the column \"condition\" is less than or equal to 2 => 'bad'.\n",
    "   - If the value of the column \"condition\" is equal to 3 or 4 => 'regular'.\n",
    "   - If the value of the column \"condition\" is equal to 5 => 'good'.\n",
    "4. Change the type of the column \"condition\" to string.\n",
    "5. Delete the columns: sqft_living15 and sqft_lot15.\n",
    "6. Change the type of the column \"yr_built\" to date.\n",
    "7. Change the type of the column \"yr_renovated\" to date.\n",
    "8. What is the earliest construction date of a property?\n",
    "9. What is the earliest date for renovation of a property?\n",
    "10. How many properties have 2 floors?\n",
    "11. How many properties have the \"condition_type\" equals to 'regular'?\n",
    "12. How many properties have the \"condition_type\" equals to 'bad' and have a water view?\n",
    "13. How many properties have the \"condition_type\" equals to 'good' and \"house_age\" equals to 'new_house'?\n",
    "14. What is the price of the most expensive property of the \"dormitory_type\" which is equal to 'studio'?\n",
    "15. How many properties of the type 'apartment' were renovated in 2015?\n",
    "16. What is the largest number of \"bedrooms\" that a property of the type 'house' has?\n",
    "17. How many properties of the type 'new_house' were renovated in 2014?\n",
    "18. Select some columns by their names, by their index and by boolean indexing. \n",
    "19. Save a .csv file with columns 10 through 17 only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46a6066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_one(data):\n",
    "    data['house_age'] = 'NA'\n",
    "    data.loc[data['date'] > '2014-01-01', 'house_age'] = \"new_house\"\n",
    "    data.loc[data['date'] < '2014-01-01', 'house_age'] = \"old_house\"\n",
    "    print(\"New dataset with column 'house_age':\\n\\n\",data.head())\n",
    "    \n",
    "    return data\n",
    "\n",
    "def question_two(data):\n",
    "    data['dormitory_type'] = 'NA'\n",
    "    data.loc[data['bedrooms'] == 1, 'dormitory_type'] = \"studio\"\n",
    "    data.loc[data['bedrooms'] == 2, 'dormitory_type'] = \"apartment\"\n",
    "    data.loc[data['bedrooms'] > 2, 'dormitory_type'] = \"house\"\n",
    "    print(\"\\n\\nNew dataset with the column 'dormitory_type':\\n\\n\",data.head())\n",
    "    \n",
    "    return data\n",
    "\n",
    "def question_three(data):\n",
    "    data['condition_type'] = 'NA'\n",
    "    data.loc[data['condition'] <= 2, 'condition_type'] = \"bad\"\n",
    "    data.loc[(data['condition'] == 3) | (data['condition'] == 4), 'condition_type'] = \"regular\"\n",
    "    data.loc[data['condition'] >= 5, 'condition_type'] = \"good\"\n",
    "    print(\"\\n\\nNew dataset with the column 'condition_type':\\n\\n\",data.head())\n",
    "    \n",
    "    return data\n",
    "\n",
    "def question_four(data):\n",
    "    print(\"\\n\\nType of the column 'condition:'\\n\\n\",data['condition'].dtypes)\n",
    "    data['condition'] = data['condition'].astype(str)\n",
    "    print(\"\\n\\nNew type of the column 'condition:'\\n\\n\",data['condition'].dtypes)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def question_five(data):\n",
    "    data.drop(['sqft_living15','sqft_lot15'], axis=1, inplace=True)\n",
    "    print(\"\\n\\nNew dataset without the columns 'sqft_living15' and 'sqft_lot15':\\n\\n\",data.head())\n",
    "    \n",
    "    return None\n",
    "\n",
    "def question_six(data):\n",
    "    data['yr_built'] = pd.to_datetime(data['yr_built'], infer_datetime_format=True, format = '%Y')\n",
    "    print(\"\\n\\nConstruction year column altered:\\n\\n\",data.head())\n",
    "    \n",
    "    return data\n",
    "\n",
    "def question_seven(data):\n",
    "    data['yr_renovated'] = pd.to_datetime(data['yr_renovated'], infer_datetime_format=True, format = '%Y')\n",
    "    print(\"\\n\\nRenvation year column altered:\\n\\n\",data.head())\n",
    "    \n",
    "    return data\n",
    "\n",
    "def question_eight(data):\n",
    "    min_year = data['yr_built'].min().year\n",
    "    print(\"\\n\\nThe earliest construction date of a property is:\",min_year)\n",
    "    \n",
    "    return min_year\n",
    "\n",
    "def question_nine(data):\n",
    "    data['min_renovated'] = 'NA'\n",
    "    for i in range(len(data)):\n",
    "\n",
    "        if data.loc[i, 'yr_renovated'].nanosecond > 900:\n",
    "            data.loc[i, 'min_renovated'] = data.loc[i, 'yr_renovated'].nanosecond\n",
    "\n",
    "        else:\n",
    "\n",
    "            data.loc[i, 'min_renovated'] = \"NA\"\n",
    "                \n",
    "    data['min_renovated'] = data['min_renovated'].astype(str)\n",
    "    min_yr = data['min_renovated'].min()\n",
    "    print(f\"\\nThe earliest renovation date is: 1{min_yr}\")\n",
    "    data = data.drop('min_renovated', axis=1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def question_ten(data):\n",
    "    two_floors = data[data['floors'] == 2].shape[0]\n",
    "    print(f\"\\n\\n{two_floors} properties have two floors.\")\n",
    "    \n",
    "    return two_floors\n",
    "\n",
    "def question_eleven(data):\n",
    "    num_reg = data[data['condition_type'] == 'regular'].shape[0]\n",
    "    print(f\"\\n\\n{num_reg} properties are 'regular'.\")\n",
    "    \n",
    "    return num_reg\n",
    "\n",
    "def question_twelve(data):\n",
    "    bad_wat = data[(data['condition_type'] == 'bad') & (data['waterfront'] > 0)].shape[0]\n",
    "    print(f\"\\n\\n{bad_wat} properties are in 'bad' condition and also have waterfront\")\n",
    "    \n",
    "    return bad_wat\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    data = question_one(data)\n",
    "    \n",
    "    data = question_two(data)\n",
    "    \n",
    "    data = question_three(data)\n",
    "    \n",
    "    data = question_four(data)\n",
    "    \n",
    "    question_five(data)\n",
    "    \n",
    "    data = question_six(data)\n",
    "    \n",
    "    data = question_seven(data)\n",
    "    \n",
    "    min_year = question_eight(data)\n",
    "    \n",
    "    data = question_nine(data)\n",
    "    \n",
    "    two_floors = question_ten(data)\n",
    "    \n",
    "    num_reg = question_eleven(data)\n",
    "    \n",
    "    bad_wat = question_twelve(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1df1d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdf530a8",
   "metadata": {},
   "source": [
    "### 2.1.4. Q&R 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafd27b6",
   "metadata": {},
   "source": [
    "1. What is the number of properties per year of construction?\n",
    "2. What is the smallest number of bedrooms per year of construction?\n",
    "3. What is the highest price per number of bedrooms?\n",
    "4. What is the sum of the price per number of bedrooms?\n",
    "5. What is the sum of the price per number of bedrooms and bathrooms?\n",
    "6. What is the average living room size per year of construction?\n",
    "7. What is the median property size per year of construction?\n",
    "8. What is the standard deviation of the living room size per year of construction?\n",
    "9. Create charts for the price by year, by day and by week.\n",
    "10. A map to visualize the properties with the highest prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c854ceba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bf4c61d",
   "metadata": {},
   "source": [
    "### 2.1.5. Q&R 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ae3460",
   "metadata": {},
   "source": [
    "1. Create a column called: dormitory_type.\n",
    "   - If the value of the column \"bedrooms\" is equal to 1 => 'studio'.\n",
    "   - If the value of the column \"bedrooms\" is equal to 2 => 'apartment'.\n",
    "   - If the value of the column \"bedrooms\" is greater than 2 => 'house'.\n",
    "2. Draw a bar chart: sum of the prices per number of bedrooms.\n",
    "3. Draw a line chart: average price per year of construction.\n",
    "4. Draw a bar chart: average price per dormitory type.\n",
    "5. Draw a line chart: price per year of renovation - since 1930.\n",
    "6. Make a table: average price per year of construction and per dormitory type.\n",
    "7. Create a dashboard with the charts of the questions 02, 03 and 04.\n",
    "8. Create a dashboard with the charts of the questions 02 and 04.\n",
    "9. Create a dashboard with the charts of the questions 03 and 05.\n",
    "10. Create a map with the points proportional to to the living room size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e95a98e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b45650ef",
   "metadata": {},
   "source": [
    "### 2.1.6. Q&R 6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d9ceb7",
   "metadata": {},
   "source": [
    "1. How many properties per level?\n",
    "   - Level 0: price between 0.00 and 321.950\n",
    "   - Level 1: price between 321.950 and 450.000\n",
    "   - Level 2: price between 450.000 and 645.000\n",
    "   - Level 3: price above 645.000\n",
    "2. Add the following information to the properties:\n",
    "   - Street;\n",
    "   - Number;\n",
    "   - Neighbourhood;\n",
    "   - City;\n",
    "   - State.\n",
    "3. Add the level of the price as a color in the map.\n",
    "4. Make the points proportional to the price in the map.\n",
    "5. Add filters to the map:\n",
    "   - Water view or not;\n",
    "   - Value of the price.\n",
    "6. Add a filter to the last dashboard:\n",
    "   - Show values only from a specific date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e87d31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da4a6f15",
   "metadata": {},
   "source": [
    "### 2.1.7. Q&R 7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f464affb",
   "metadata": {},
   "source": [
    "Deploy to Heroku a portfolio as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcad61d7",
   "metadata": {},
   "source": [
    "1. Add filters by region.\n",
    "2. Choose attributes to visualize.\n",
    "3. Total number of properties by zipcode, average by zipcode, average living room size by zipcode and average price per square meters by zipcode. \n",
    "4. Descriptive analysis for each column.\n",
    "5. Daily and annual price fluctuation.\n",
    "6. Properties distributed by: price, number of bedrooms, number of bathrooms, number of floors and waterfront."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ace47b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30591ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
