{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df658999",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46a798a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df83b2a2",
   "metadata": {},
   "source": [
    "# 1.0. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b94e9ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset upload from URL\n",
    "url = 'https://raw.githubusercontent.com/lucasquemelli/House_Rocket/main/kc_house_data.csv'\n",
    "data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0bdd3e",
   "metadata": {},
   "source": [
    "## 1.1. Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ba8c252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualization of the first 05 rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44135ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_shape(data):\n",
    "    print(\"Shape of the dataset\")\n",
    "    print(\"\\nNumber of rows: {}\\nNumber of columns: {}\".format(data.shape[0],data.shape[1]))\n",
    "    \n",
    "    return None\n",
    "\n",
    "def num_attributes(data):\n",
    "    num_attributes = len(data.columns) - 2\n",
    "    print(\"\\n\\nThe number of attribute is:\", num_attributes)\n",
    "    \n",
    "    return num_attributes\n",
    "\n",
    "def attributes(data):\n",
    "    attributes = data.drop(['id','date'], axis=1)\n",
    "    print(\"\\n\\nThe attributes are:\\n\\n\",attributes.columns.tolist())\n",
    "    \n",
    "    return attributes\n",
    "\n",
    "def data_info(data):\n",
    "    print(\"\\n\\nData types\\n\")\n",
    "    data.info()\n",
    "    \n",
    "    return None\n",
    "\n",
    "def descriptive_analysis(data):\n",
    "    pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "    print(\"\\n\\nDescriptive analysis:\\n\\n\",data.describe().T)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def display(data):\n",
    "    #Displaying unique values for the number of bedrooms, bathrooms, floors, waterfront, view, condition and grade\n",
    "    print(\"\\n\\nAttributes unique values\")\n",
    "    print(\"\\n\\nUnique values for bedrooms:\", np.sort(data['bedrooms'].unique())) \n",
    "    print(\"\\nUnique values for bathrooms:\", np.sort(data['bathrooms'].unique()))\n",
    "    print(\"\\nUnique values for floors:\", np.sort(data['floors'].unique()))\n",
    "    print(\"\\nUnique values for waterfront:\", np.sort(data['waterfront'].unique()))\n",
    "    print(\"\\nUnique values for view:\", np.sort(data['view'].unique()))\n",
    "    print(\"\\nUnique values for condition:\", np.sort(data['condition'].unique()))\n",
    "    print(\"\\nUnique values for grade:\", np.sort(data['grade'].unique()))\n",
    "\n",
    "    print(\"\\n\\nWhile there are properties with 33 bedrooms, also are there with 0. The same happens with the number of bathrooms. This would properly be classified as inconsistences, yet I choose to classify into different types of properties in this analysis.\")\n",
    "    print(\"\\n\\nThe other attributes contain a large number of unique values, such as 'id' - as it may be seen below. Thus, they were not considered in this analysis.\")\n",
    "\n",
    "    print(\"\\n\\nNumber of unique values for 'id':\", data['id'].nunique())\n",
    "    print(\"\\n\\nWhile the number of rows is 21613, the number of unique 'id' is 21436. It means there are only 21436 properties.\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    data_shape(data)\n",
    "    \n",
    "    num_attributes = num_attributes(data)\n",
    "    \n",
    "    attributes = attributes(data)\n",
    "    \n",
    "    data_info(data)\n",
    "    \n",
    "    descriptive_analysis(data)\n",
    "    \n",
    "    display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956a626f",
   "metadata": {},
   "source": [
    "**Meaning of the attributes**\n",
    "\n",
    "- ID: identification number\n",
    "- date: period in which the properties were available\n",
    "- bedrooms: number of bedrooms\n",
    "- bathrooms: number of bathrooms\n",
    "- floors: number of floors\n",
    "- waterfront: if some property has waterfront or not (0 or 1)\n",
    "- view: number of views\n",
    "- condition: condition of the properties (1 to 5)\n",
    "- grade: quality of the building and construction level\n",
    "- price: price of the property\n",
    "- sqft_living: living room built area [ftÂ²]\n",
    "- sqft_lot: lot area [ftÂ²]\n",
    "- sqft_above: built area above ground level [ftÂ²]\n",
    "- sqft_basement: built basement area [ftÂ²]\n",
    "- yr_built: year that the property was built\n",
    "- yr_renovated: year of renovation\n",
    "- sqft_living15: average built area of the 15 nearest neighboring properties [ftÂ²]\n",
    "- sqft_lot15: average lot area of the 15 nearest neighboring properties [ftÂ²]\n",
    "- zipcode: number of zipcode\n",
    "- lat: latitude identification number\n",
    "- long: longitude identification number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a947e13",
   "metadata": {},
   "source": [
    "## 1.2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c432f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values(data):\n",
    "    print(\"Missing values\\n\")\n",
    "    print(data.isna().sum())\n",
    "    \n",
    "    return None\n",
    "\n",
    "def ids(data):\n",
    "    ids = data['id']\n",
    "    \n",
    "    return ids\n",
    "\n",
    "def duplicates_id(data):\n",
    "    print(\"\\n\\nDuplicates\\n\")\n",
    "    print(data[ids.isin(ids[ids.duplicated()])].sort_values('id'))\n",
    "    \n",
    "    return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    missing_values(data)\n",
    "    \n",
    "    ids = ids(data)\n",
    "    \n",
    "    duplicates_id(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29e9b27",
   "metadata": {},
   "source": [
    "Duplicates (353) in this dataset are meant to be properties which were sold twice or more between 2014 and 2015. These properties were sold on different dates and at different prices. It means the price changes with time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8989e87c",
   "metadata": {},
   "source": [
    "It is important to mention that the number of duplicates is different from the number of ids that are duplicates. Notice that the same id appears twice or more. Thus, the number of ids that are duplicate is: total number of rows - number of unique ids = 177."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fd7c4d",
   "metadata": {},
   "source": [
    "## 1.3. Data Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c738a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversiong to datetime\n",
    "data['date'] =  pd.to_datetime(data['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1b488e",
   "metadata": {},
   "source": [
    "## 1.4. Outliers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b9203e",
   "metadata": {},
   "source": [
    "We may have a look at the outliers in the dataset using the boxplot chart. However, as it may be seen below, this is an univariate analysis. As the price is influenced by a lot of features in the dataset, we must remove outliers using multivariate analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf601ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y='price',data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c6009d",
   "metadata": {},
   "source": [
    "To remove outliers using multivariate analysis, we are going to use three methods: **visual method**, **Z-score method** and **interquartile range method**. Then, we are going to work *separately* with each resulting dataset and make conclusions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ea9dd9",
   "metadata": {},
   "source": [
    "Firstly, in order to use the methods **Z-score** and **interquartile range**, we have to set the column 'date' as integer as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2f9f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the feature 'date' as integer (type 1)\n",
    "df1 = data\n",
    "df1['date'] = df1['date'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f76fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the feature 'date' as integer (type 2)\n",
    "df1 = data\n",
    "df1['date'] = df1['date'].view(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eec066",
   "metadata": {},
   "source": [
    "The dataset df1 is the same in the two cases above. It was only treated with two different \"set as integer\" functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c1ad12",
   "metadata": {},
   "source": [
    "### 1.4.1. Visual method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28b26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Properties with the highest prices\n",
    "data.sort_values('price', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9e1488",
   "metadata": {},
   "source": [
    "The properties with the highest prices have such values due to their features. No anomalies were found to be considered as outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931cb404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Properties with 10 or more than 10 bedrooms\n",
    "data[data['bedrooms'] >= 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed861ac8",
   "metadata": {},
   "source": [
    "The prices of the properties above are all feasible with their features. Although perhaps the 11-bedrooms and the 33-bedrooms properties prices may be seen as anomalies, they will not be treated as outliers due to their year built (yr_built) and total area (sqft_lot). Some of their features may be atypical because of the time they were built and localization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f666e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Properties with no bedrooms\n",
    "data[data['bedrooms'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9271e338",
   "metadata": {},
   "source": [
    "Although some properties have no bedrooms, they may be treated as studios and not as apartments or even houses. They are considered like this and not as outliers due to requests from the House Rocket's CEO. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dedeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Properties with 6 or more than 6 bathrooms\n",
    "data[data['bathrooms'] >= 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799375d9",
   "metadata": {},
   "source": [
    "The prices of the properties above are all consistent with their features. Thus, they will not be treated as outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febb00de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Properties with no bathrooms\n",
    "data[data['bathrooms'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d5b8d1",
   "metadata": {},
   "source": [
    "The properties above - with no bathrooms - will be treated as outliers, since there is not a classification for them. Assuming they are a typo, these rows will be removed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec68d9c",
   "metadata": {},
   "source": [
    "#### 1.4.1.1 Dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d810d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows(data):\n",
    "    data = data.drop(data[data['bathrooms'] == 0].index)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def reset_index(data):\n",
    "    data = data.reset_index(drop=True)\n",
    "    dataset = data.copy()\n",
    "    \n",
    "    return data, dataset\n",
    "\n",
    "def show_dimensions(data):\n",
    "    print(f\"Clean dataset: {data.shape[0]} properties (rows), {data.shape[1]} features (columns).\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    data = drop_rows(data)\n",
    "    \n",
    "    data, dataset = reset_index(data)\n",
    "    \n",
    "    show_dimensions(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3674fa",
   "metadata": {},
   "source": [
    "### 1.4.2. Z-score method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bcb42e",
   "metadata": {},
   "source": [
    "\"The Z-score is the signed number of standard deviations by which the value of an observation or data point is above the mean value of what is being observed or measured.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f35eecc",
   "metadata": {},
   "source": [
    "\"The intuition behind Z-score is to describe any data point by finding their relationship with the Standard Deviation and Mean of the group of data points. Z-score is finding the distribution of data where mean is 0 and standard deviation is 1 i.e. normal distribution.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b68ea85",
   "metadata": {},
   "source": [
    "\"Calculating the Z-score, we re-scale and center the data and look for data points which are too far from zero. These data points which are way too far from zero will be treated as the outliers.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a12846",
   "metadata": {},
   "source": [
    "In this case (project), a threshold of 3 was used. For instance, when the Z-score value was greater than 3, that data point was identified as an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3042de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardization_data(df1):\n",
    "    z1 = np.abs(stats.zscore(df1))\n",
    "    print(\"Standardized dataset:\\n\\n\", z1)\n",
    "    \n",
    "    return z1\n",
    "\n",
    "def show_index_outliers(z1):\n",
    "    #Defining threshold as 3\n",
    "    threshold = 3\n",
    "    \n",
    "    print(\"\\n\\nIndexes of the outliers:\\n\\n\",np.where(z1 > 3))\n",
    "    \n",
    "    return None\n",
    "\n",
    "def show_first_outlier(z1):\n",
    "    print(\"\\n\\nValue of the first outlier:\\n\\n\",z1.iloc[1][15])\n",
    "    \n",
    "    return None\n",
    "\n",
    "def removing_outliers(df1, z1):\n",
    "    df2 = df1[(z1 < 3).all(axis=1)]\n",
    "    \n",
    "    return df2\n",
    "\n",
    "def show_new_shape(df2):\n",
    "    print(\"\\n\\nShape of the clean dataset:\\n\\nNumber of rows:\", df2.shape[0])\n",
    "    print(\"Number of columns:\", df2.shape[1])\n",
    "    \n",
    "    return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    z1 = standardization_data(df1)\n",
    "    \n",
    "    show_index_outliers(z1)\n",
    "    \n",
    "    show_first_outlier(z1)\n",
    "    \n",
    "    df2 = removing_outliers(df1, z1)\n",
    "    \n",
    "    show_new_shape(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1766867e",
   "metadata": {},
   "source": [
    "### 1.4.3. Interquartile range (IQR) method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb4a079",
   "metadata": {},
   "source": [
    "Box plot use the IQR method to display data and outliers(shape of the data). The interquartile range (IQR) is a measure of statistical dispersion, being equal to the difference between 75th and 25th percentiles, or between upper and lower quartiles, IQR = Q3 âˆ’ Q1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce20d80",
   "metadata": {},
   "source": [
    "\"It is a measure of the dispersion similar to standard deviation or variance, but is much more robust against outliers.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdfe2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quartiles(df1):\n",
    "    Q1 = df1.quantile(0.25)\n",
    "    Q3 = df1.quantile(0.75)\n",
    "    \n",
    "    return Q1, Q3\n",
    "\n",
    "def IQR_function(Q1, Q3):\n",
    "    IQR = Q3 - Q1\n",
    "    print(\"Interquartile range:\\n\\n\",IQR)\n",
    "    \n",
    "    return IQR\n",
    "\n",
    "def show_boolean_outliers(df1, Q1, Q3, IQR):\n",
    "    print(\"\\n\\nBoolean values:\\n\\n\",(df1 < (Q1 - 1.5 * IQR)) | (df1 > (Q3 + 1.5 * IQR)))\n",
    "    \n",
    "    return None\n",
    "\n",
    "def removing_outliers(df1, Q1, Q3, IQR):\n",
    "    df3 = df1[~((df1 < (Q1 - 1.5 * IQR)) | (df1 > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "    \n",
    "    return df3\n",
    "\n",
    "def show_dimensions_dataset(df3):\n",
    "    print(\"\\n\\nShape of the clean dataset:\\n\\n\",df3.shape)\n",
    "    \n",
    "    return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    Q1, Q3 = quartiles(df1)\n",
    "    \n",
    "    IQR = IQR_function(Q1, Q3)\n",
    "    \n",
    "    show_boolean_outliers(df1, Q1, Q3, IQR)\n",
    "    \n",
    "    df3 = removing_outliers(df1, Q1, Q3, IQR)\n",
    "    \n",
    "    show_dimensions_dataset(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95fe17c",
   "metadata": {},
   "source": [
    "### 1.4.4. Outliers choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077afdce",
   "metadata": {},
   "source": [
    "After tested the three methods to identify and remove outliers, I decided to choose the **visual method**. The choice was made based on number of rows which were removed, since the **Z-score and IQR methods** overexcluded the elements in the dataset without consider particular features of each property. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f363615",
   "metadata": {},
   "source": [
    "# 2.0. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3f59c5",
   "metadata": {},
   "source": [
    "## 2.1. Questions and Requests (Q&R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915cd89a",
   "metadata": {},
   "source": [
    "In order to find the most important attributes related to the price and hence improving the decision making, House Rocket's CEO created 7 sets of questions and requests. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9371ba",
   "metadata": {},
   "source": [
    "### 2.1.1. Q&R 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41f19ca",
   "metadata": {},
   "source": [
    "1. How many properties are available for purchase?\n",
    "2. How many attributes do properties have?\n",
    "3. What are the attributes of the properties?\n",
    "4. What is the most expensive property? (with the highest sale price)\n",
    "5. What property has the largest number of bedrooms?\n",
    "6. What is the total sum of the number of bedrooms in the dataset?\n",
    "7. How many properties have two bathrooms?\n",
    "8. What is the average price of all properties in the dataset?\n",
    "9. What is the average price of the properties with two bathrooms?\n",
    "10. What is the minimum price for the 3-bedrooms properties?\n",
    "11. How many properties have more than 300 square meters in the living room?\n",
    "12. How many properties have more than two floors?\n",
    "13. How many properties have a waterfront?\n",
    "14. Among properties with a waterfront, how many have three bedrooms?\n",
    "15. Among properties with more than 300 square meters in the living room, how many have more than two bathrooms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f311fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_one(data):\n",
    "    num = data['id'].nunique()\n",
    "    print(\"There are \", num,\" properties available for purchase.\")\n",
    "    \n",
    "    return num\n",
    "\n",
    "def question_two(data):\n",
    "    num_attributes = len(data.columns) - 2\n",
    "    print(\"\\n\\nThe properties have \",num_attributes,\" attributes\")\n",
    "    \n",
    "    return num_attributes\n",
    "\n",
    "def question_three(data):\n",
    "    attributes = data.drop(['id','date'],axis=1)\n",
    "    print(\"\\n\\nThe attributes are:\\n\\n\",attributes.columns.tolist())\n",
    "    \n",
    "    return attributes\n",
    "\n",
    "def question_four(data):\n",
    "    m_e_h = data[['id','price']].sort_values('price',ascending=False)\n",
    "    print(\"\\n\\nMost expensive properties:\\n\")\n",
    "    print(m_e_h)\n",
    "\n",
    "    most_expensive = data[['id','price']].sort_values('price',ascending=False).iloc[0,0]\n",
    "    print(\"\\n\\nThe most expensive property has the id:\",most_expensive)\n",
    "    \n",
    "    return m_e_h, most_expensive\n",
    "\n",
    "def question_five(data):\n",
    "    m_n_h = data[['id','bedrooms']].sort_values('bedrooms',ascending=False)\n",
    "    print(\"\\n\\nThe property with the largest number of bedrooms is in the first line:\\n\\n\",m_n_h)\n",
    "    \n",
    "    return m_n_h\n",
    "\n",
    "def question_six(data):\n",
    "    sum_bedrooms = data['bedrooms'].sum()\n",
    "    print(\"\\n\\nThe dataset total sum of bedrooms is:\",sum_bedrooms)\n",
    "    \n",
    "    return sum_bedrooms\n",
    "\n",
    "def question_seven(data):\n",
    "    dataframe = data.loc[data['bathrooms'] ==2,:]\n",
    "    number = len(dataframe)\n",
    "    print(\"\\n\\nThe number of properties with two bathrooms is:\", number)\n",
    "    \n",
    "    return dataframe\n",
    "    \n",
    "def question_eight(data):\n",
    "    average_price = np.round(data['price'].mean(),2)\n",
    "    print(\"\\n\\nThe average price of all properties is: ${}\".format(average_price))\n",
    "    \n",
    "    return average_price\n",
    "\n",
    "def question_nine(data):\n",
    "    avg_bath = np.round(data.loc[data['bathrooms']==2,'price'].mean(),2)\n",
    "    print(\"\\n\\nThe average price of the properties with 02 bathrooms is: ${}\".format(avg_bath))\n",
    "    \n",
    "    return avg_bath\n",
    "\n",
    "def question_ten(data):\n",
    "    min_price = np.round(data.loc[data['bedrooms']==3,'price'].min(),2)\n",
    "    print(\"\\n\\nThe minimum price of a 03-bedrooms property is: ${}\".format(min_price))\n",
    "    \n",
    "    return min_price\n",
    "\n",
    "def question_eleven(data):\n",
    "    more_300 = data.loc[data['sqft_living']>300,:]\n",
    "    num_ = len(more_300)\n",
    "    #print(\"\\n\\nThe number of properties with more than 300 mÂ² is:\",num_)\n",
    "\n",
    "    num_ = data.loc[data['sqft_living']>300,:].shape[0]\n",
    "    print(\"\\n\\nThe number of properties with more than 300 mÂ² is:\",num_)\n",
    "    \n",
    "    return more_300, num_\n",
    "\n",
    "def question_twelve(data):\n",
    "    two_floors = data.loc[data['floors']>2,:].shape[0]\n",
    "    print(\"\\n\\nThe number of properties with more than 02 floors is:\", two_floors)\n",
    "    \n",
    "    return two_floors\n",
    "\n",
    "def question_thirteen(data):\n",
    "    water_front = data.loc[data['waterfront']>0,:].shape[0]\n",
    "    print(\"\\n\\nThe number of properties with waterfront view is:\",water_front)\n",
    "    \n",
    "    return water_front\n",
    "\n",
    "def question_fourteen(data):\n",
    "    water_three = data.loc[(data['waterfront']>0) & (data['bedrooms']==3),:].shape[0]\n",
    "    print(\"\\n\\nThe number of properties with waterfront view and more than 03 bedrooms is:\",water_three)\n",
    "    \n",
    "    return water_three\n",
    "\n",
    "def question_fifteen(data):    \n",
    "    houses = data.loc[(data['sqft_living']>300) & (data['bathrooms']>2),:].shape[0]\n",
    "    print(\"\\n\\nThe number of properties with more than 300 mÂ² and more than 02 bathrooms is:\",houses)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    num =  question_one(data)\n",
    "\n",
    "    num_attributes = question_two(data)\n",
    "\n",
    "    attributes = question_three(data)\n",
    "\n",
    "    m_e_h, most_expensive = question_four(data)\n",
    "\n",
    "    m_n_h = question_five(data)\n",
    "    \n",
    "    sum_bedrooms = question_six(data)\n",
    "\n",
    "    dataframe = question_seven(data)\n",
    "    \n",
    "    average_price = question_eight(data)\n",
    "    \n",
    "    avg_bath = question_nine(data)\n",
    " \n",
    "    min_price = question_ten(data)\n",
    "\n",
    "    num_ = question_eleven(data)\n",
    "\n",
    "    two_floors = question_twelve(data)\n",
    "\n",
    "    water_front = question_thirteen(data)\n",
    "\n",
    "    water_three = question_fourteen(data)\n",
    "  \n",
    "    houses = question_fifteen(data)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d314fc",
   "metadata": {},
   "source": [
    "### 2.1.2. Q&R 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d81c20c",
   "metadata": {},
   "source": [
    "1. What is the date of the oldest property in the portfolio?\n",
    "2. How many properties have the maximum number of floors?\n",
    "3. Create a low and high standard classification for properties:\n",
    "   - High standard: above USD 540000.00.\n",
    "   - Low standard: below USD 540000.00.\n",
    "4. Make a report (.csv file) ordered by price with the following information:\n",
    "   - Property ID;\n",
    "   - Date the property became available for purchase;\n",
    "   - Number of bedrooms;\n",
    "   - Total land size;\n",
    "   - Price;\n",
    "   - Property classification.\n",
    "5. A map where the houses are located geographically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb89d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_types(data):\n",
    "    print(\"Data types\\n\\n\",data.dtypes)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def conversion_date(data):\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    \n",
    "    return data\n",
    "\n",
    "def question_one(data):\n",
    "    min_port = data['date'].min()\n",
    "    print(\"\\n\\nThe earliest date which a property became available for purchase in the portfolio is:\",min_port)\n",
    "    \n",
    "    return min_port\n",
    "\n",
    "def question_two(data):\n",
    "    max_floors = data[data['floors'] == 3.5].shape[0]\n",
    "    print(f\"\\n\\n{max_floors} properties have the maximum number of floors.\")\n",
    "    \n",
    "    return max_floors\n",
    "\n",
    "def question_three(data):\n",
    "    data['classification'] = 'NA'\n",
    "    print(\"\\n\\nCreation of the classification column:\\n\\n\",data.columns)\n",
    "    data.loc[data['price'] > 540000, 'classification'] = \"high_standard\"\n",
    "    data.loc[data['price'] < 540000, 'classification'] = \"low_standard\"\n",
    "    print(\"\\n\\n\",data.head())\n",
    "    \n",
    "    return data\n",
    "\n",
    "def question_four(data):    \n",
    "    report = data[['id','date','bedrooms','sqft_lot','price','classification']].sort_values('price',ascending=False)\n",
    "    print(\"\\n\\nReport:\\n\\n\",report)\n",
    "    report.to_csv(\"report.csv\",index=False)\n",
    "    \n",
    "    return report\n",
    "\n",
    "#def question_five(data):\n",
    "#    data_map = data[['id','lat','long','price']]\n",
    "#    fig_map = px.scatter_mapbox(data_map, lat='lat', lon='long', hover_name='id', hover_data =['price'], zoom = 3, height = 300)\n",
    "\n",
    "#    fig_map.update_layout(mapbox_style ='open-street-map', height = 600, margin = {\"r\": 0, \"l\": 0, \"t\": 0, \"b\": 0})\n",
    "    \n",
    "#    print(\"\\n\\nMap\\n\\n\")\n",
    "\n",
    "#    fig_map.show()\n",
    "    \n",
    "#    fig_map.write_html(\"first_map.html\")\n",
    "    \n",
    "#    return data_map, fig_map\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data_types(data)\n",
    "    \n",
    "    data = conversion_date(data)\n",
    "    \n",
    "    min_port = question_one(data)\n",
    "    \n",
    "    max_floors = question_two(data)\n",
    "    \n",
    "    data = question_three(data)\n",
    "    \n",
    "    report = question_four(data)\n",
    "    \n",
    "#    data_map, fig_map = question_five(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54fdde7",
   "metadata": {},
   "source": [
    "The map made was too big to be visualized on *GitHub*. That's why the question five was marked with \"#\" to avoid its answer. Yet, the code lines are still available above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2977c91d",
   "metadata": {},
   "source": [
    "As an alternative solution, the map was deployed to Heroku: [Property map.](https://property-map-quemelli-lucas.herokuapp.com/). The script to this procedure may be found in the folders named \"Q&R => Q&R 2.0\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b5d7cb",
   "metadata": {},
   "source": [
    "### 2.1.3. Q&R 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc5f292",
   "metadata": {},
   "source": [
    "1. Create a column called: house_age. \n",
    "   - If the value of the column \"date\" is greater than 2014-01-01 => 'new_house'.\n",
    "   - If the value of the column \"date\" is less than 2014-01-01 => 'old_house'.  \n",
    "2. Create a column called: dormitory_type.\n",
    "   - If the value of the column \"bedrooms\" is equal to 1 => 'studio'.\n",
    "   - If the value of the column \"bedrooms\" is equal to 2 => 'apartment'.\n",
    "   - If the value of the column \"bedrooms\" is greater than 2 => 'house'.\n",
    "3. Create a column called: condition_type.\n",
    "   - If the value of the column \"condition\" is less than or equal to 2 => 'bad'.\n",
    "   - If the value of the column \"condition\" is equal to 3 or 4 => 'regular'.\n",
    "   - If the value of the column \"condition\" is equal to 5 => 'good'.\n",
    "4. Change the type of the column \"condition\" to string.\n",
    "5. Delete the columns: sqft_living15 and sqft_lot15.\n",
    "6. Change the type of the column \"yr_built\" to date.\n",
    "7. Change the type of the column \"yr_renovated\" to date.\n",
    "8. What is the earliest construction date of a property?\n",
    "9. What is the earliest date for renovation of a property?\n",
    "10. How many properties have 2 floors?\n",
    "11. How many properties have the \"condition_type\" equals to 'regular'?\n",
    "12. How many properties have the \"condition_type\" equals to 'bad' and have a water view?\n",
    "13. How many properties have the \"condition_type\" equals to 'good' and \"house_age\" equals to 'new_house'?\n",
    "14. What is the price of the most expensive property of the \"dormitory_type\" which is equal to 'studio'?\n",
    "15. How many properties of the type 'apartment' were renovated in 2015?\n",
    "16. What is the maximum number of \"bedrooms\" that a property of the type 'house' has?\n",
    "17. How many properties of the type 'new_house' were renovated in 2014?\n",
    "18. Select some columns by their names, by their index and by boolean indexing. \n",
    "19. Save a .csv file with columns 10 through 17 only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46a6066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_one(data):\n",
    "    data['house_age'] = 'NA'\n",
    "    data.loc[data['date'] > '2014-01-01', 'house_age'] = \"new_house\"\n",
    "    data.loc[data['date'] < '2014-01-01', 'house_age'] = \"old_house\"\n",
    "    print(\"New dataset with column 'house_age':\\n\\n\",data.head())\n",
    "    \n",
    "    return data\n",
    "\n",
    "def question_two(data):\n",
    "    data['dormitory_type'] = 'NA'\n",
    "    data.loc[data['bedrooms'] == 1, 'dormitory_type'] = \"studio\"\n",
    "    data.loc[data['bedrooms'] == 2, 'dormitory_type'] = \"apartment\"\n",
    "    data.loc[data['bedrooms'] > 2, 'dormitory_type'] = \"house\"\n",
    "    print(\"\\n\\nNew dataset with the column 'dormitory_type':\\n\\n\",data.head())\n",
    "    \n",
    "    return data\n",
    "\n",
    "def question_three(data):\n",
    "    data['condition_type'] = 'NA'\n",
    "    data.loc[data['condition'] <= 2, 'condition_type'] = \"bad\"\n",
    "    data.loc[(data['condition'] == 3) | (data['condition'] == 4), 'condition_type'] = \"regular\"\n",
    "    data.loc[data['condition'] >= 5, 'condition_type'] = \"good\"\n",
    "    print(\"\\n\\nNew dataset with the column 'condition_type':\\n\\n\",data.head())\n",
    "    \n",
    "    return data\n",
    "\n",
    "def question_four(data):\n",
    "    print(\"\\n\\nType of the column 'condition:'\\n\\n\",data['condition'].dtypes)\n",
    "    data['condition'] = data['condition'].astype(str)\n",
    "    print(\"\\n\\nNew type of the column 'condition:'\\n\\n\",data['condition'].dtypes)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def question_five(data):\n",
    "    data.drop(['sqft_living15','sqft_lot15'], axis=1, inplace=True)\n",
    "    print(\"\\n\\nNew dataset without the columns 'sqft_living15' and 'sqft_lot15':\\n\\n\",data.head())\n",
    "    \n",
    "    return None\n",
    "\n",
    "def question_six(data):\n",
    "    data['yr_built'] = pd.to_datetime(data['yr_built'], infer_datetime_format=True, format = '%Y')\n",
    "    print(\"\\n\\nConstruction year column altered:\\n\\n\",data.head())\n",
    "    \n",
    "    return data\n",
    "\n",
    "def question_seven(data):\n",
    "    data['yr_renovated'] = pd.to_datetime(data['yr_renovated'], infer_datetime_format=True, format = '%Y')\n",
    "    print(\"\\n\\nRenvation year column altered:\\n\\n\",data.head())\n",
    "    \n",
    "    return data\n",
    "\n",
    "def question_eight(data):\n",
    "    min_year = data['yr_built'].min().year\n",
    "    print(\"\\n\\nThe earliest construction date of a property is:\",min_year)\n",
    "    \n",
    "    return min_year\n",
    "\n",
    "def question_nine(data):\n",
    "    data['min_renovated'] = 'NA'\n",
    "    for i in range(len(data)):\n",
    "\n",
    "        if data.loc[i, 'yr_renovated'].nanosecond > 900:\n",
    "            data.loc[i, 'min_renovated'] = data.loc[i, 'yr_renovated'].nanosecond\n",
    "\n",
    "        else:\n",
    "\n",
    "            data.loc[i, 'min_renovated'] = \"NA\"\n",
    "                \n",
    "    data['min_renovated'] = data['min_renovated'].astype(str)\n",
    "    min_yr = data['min_renovated'].min()\n",
    "    print(f\"\\nThe earliest renovation date is: 1{min_yr}\")\n",
    "    data = data.drop('min_renovated', axis=1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def question_ten(data):\n",
    "    two_floors = data[data['floors'] == 2].shape[0]\n",
    "    print(f\"\\n\\n{two_floors} properties have two floors.\")\n",
    "    \n",
    "    return two_floors\n",
    "\n",
    "def question_eleven(data):\n",
    "    num_reg = data[data['condition_type'] == 'regular'].shape[0]\n",
    "    print(f\"\\n\\n{num_reg} properties are 'regular'.\")\n",
    "    \n",
    "    return num_reg\n",
    "\n",
    "def question_twelve(data):\n",
    "    bad_wat = data[(data['condition_type'] == 'bad') & (data['waterfront'] > 0)].shape[0]\n",
    "    print(f\"\\n\\n{bad_wat} properties are in 'bad' condition and also have waterfront.\")\n",
    "    \n",
    "    return bad_wat\n",
    "\n",
    "def question_thirteen(data):\n",
    "    good_new = data[(data['condition_type'] == 'good') & (data['house_age'] == 'new_house')].shape[0]\n",
    "    print(f\"\\n\\n{good_new} properties are in condition type equals to 'good' and also are 'new_house'.\")\n",
    "    \n",
    "    return good_new\n",
    "\n",
    "def question_fourteen(data):\n",
    "    max_st = data[data['dormitory_type'] == 'studio']['price'].max()\n",
    "    print(f\"\\n\\nThe most expensive studio costs ${max_st}.\")\n",
    "    \n",
    "    return max_st\n",
    "\n",
    "def question_fifteen(data):\n",
    "    data['ap_renovated'] = 'NA'\n",
    "    for i in range(len(data)):\n",
    "\n",
    "        if data.loc[i, 'yr_renovated'].nanosecond == 0o15:\n",
    "            data.loc[i, 'ap_renovated'] = data.loc[i, 'yr_renovated'].nanosecond\n",
    "\n",
    "        else:\n",
    "\n",
    "            data.loc[i, 'ap_renovated'] = \"NA\"\n",
    "                \n",
    "    ap_reno = data[(data['dormitory_type'] == 'apartment') & (data['ap_renovated'] == 0o15)].shape[0]\n",
    "    print(f\"\\n\\n{ap_reno} apartments were renovated in 2015.\")\n",
    "    data = data.drop('ap_renovated', axis=1)\n",
    "    \n",
    "    return data, ap_reno\n",
    "\n",
    "def question_sixteen(data):\n",
    "    max_bed = data[data['dormitory_type'] == 'house']['bedrooms'].max()\n",
    "    print(f\"\\n\\nThe maximum number of bedrooms that a property has in the dataset is {max_bed}.\")\n",
    "    \n",
    "    return max_bed\n",
    "\n",
    "def question_seventeen(data):\n",
    "    data['newh_renovated'] = 'NA'\n",
    "    for i in range(len(data)):\n",
    "\n",
    "        if data.loc[i, 'yr_renovated'].nanosecond == 0o14:\n",
    "            data.loc[i, 'newh_renovated'] = data.loc[i, 'yr_renovated'].nanosecond\n",
    "\n",
    "        else:\n",
    "\n",
    "            data.loc[i, 'newh_renovated'] = \"NA\"\n",
    "                \n",
    "    newh_reno = data[(data['house_age'] == 'new_house') & (data['newh_renovated'] == 0o14)].shape[0]\n",
    "    print(f\"\\n\\n{newh_reno} properties classified as 'new_house' were renovated in 2014.\")\n",
    "    data = data.drop('newh_renovated', axis=1)\n",
    "    \n",
    "    return data, newh_reno\n",
    "\n",
    "def question_eighteen(data):\n",
    "    print(\"\\n\\nSelection of columns by their names:\\n\\n\")\n",
    "    print(data[['id','date','price','floors','zipcode']])\n",
    "    \n",
    "    print(\"\\n\\nSelection of columns by their indexes:\\n\\n\")\n",
    "    print(data.iloc[:,[0,1,2,7,16]])\n",
    "    \n",
    "    print(\"\\n\\nSelection of columns by their indexes and names:\\n\\n\")\n",
    "    print(data.loc[:,['id','date','price','floors','zipcode']])\n",
    "    \n",
    "    print(\"\\n\\nSelection of columns by boolean indexing:\\n\\n\")\n",
    "    cols = [True, True, True, False, False, False, False, True, False, False, False, False, False, False, False, False, True, \n",
    "            False, False, False, False, False, False]\n",
    "    print(data.loc[:,cols])\n",
    "    \n",
    "    return None\n",
    "\n",
    "def question_nineteen(data):\n",
    "    report = data.iloc[:, 10:17]\n",
    "    report.to_csv(\"report_two.csv\", index = False)\n",
    "    \n",
    "    return report\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    data = question_one(data)\n",
    "    \n",
    "    data = question_two(data)\n",
    "    \n",
    "    data = question_three(data)\n",
    "    \n",
    "    data = question_four(data)\n",
    "    \n",
    "    question_five(data)\n",
    "    \n",
    "    data = question_six(data)\n",
    "    \n",
    "    data = question_seven(data)\n",
    "    \n",
    "    min_year = question_eight(data)\n",
    "    \n",
    "    data = question_nine(data)\n",
    "    \n",
    "    two_floors = question_ten(data)\n",
    "    \n",
    "    num_reg = question_eleven(data)\n",
    "    \n",
    "    bad_wat = question_twelve(data)\n",
    "    \n",
    "    good_new = question_thirteen(data)\n",
    "    \n",
    "    max_st = question_fourteen(data)\n",
    "    \n",
    "    data, ap_reno = question_fifteen(data)\n",
    "    \n",
    "    max_bed = question_sixteen(data)\n",
    "    \n",
    "    data, newh_reno = question_seventeen(data)\n",
    "    \n",
    "    question_eighteen(data)\n",
    "    \n",
    "    report = question_nineteen(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf530a8",
   "metadata": {},
   "source": [
    "### 2.1.4. Q&R 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafd27b6",
   "metadata": {},
   "source": [
    "1. What is the number of properties per construction year?\n",
    "2. What is the smallest number of bedrooms per construction year?\n",
    "3. What is the highest price of a property per number of bedrooms?\n",
    "4. What is the sum of the prices per number of bedrooms?\n",
    "5. What is the sum of the prices per number of bedrooms and bathrooms?\n",
    "6. What is the living room average area per construction year?\n",
    "7. What is the median property size per construction year?\n",
    "8. What is the standard deviation of the living room size per construction year?\n",
    "9. Create charts for the price by year, by day and by week.\n",
    "10. A map to visualize the properties with the highest prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c854ceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_one(dataset):\n",
    "    per_yr = dataset[['id','yr_built']].groupby('yr_built').count()\n",
    "    per_yr.rename(columns={'id':'Number of properties'}, inplace=True)\n",
    "    per_yr.index.name = 'Construction year'\n",
    "    print(\"Number of properties per construction year:\\n\\n\")\n",
    "    print(per_yr)\n",
    "    \n",
    "    return per_yr\n",
    "\n",
    "def question_two(dataset):\n",
    "    min_bed_yr = dataset[['bedrooms','yr_built']].groupby('yr_built').min()\n",
    "    min_bed_yr.rename(columns={'bedrooms':'Number of bedrooms'}, inplace=True)\n",
    "    min_bed_yr.index.name = 'Construction year'\n",
    "    print(\"\\n\\nThe smallest number of bedrooms per construction year:\\n\\n\")\n",
    "    print(min_bed_yr)\n",
    "    \n",
    "    return min_bed_yr\n",
    "\n",
    "def question_three(data):\n",
    "    max_price_bed = data[['price','bedrooms']].groupby('bedrooms').max()\n",
    "    max_price_bed.index.name = 'Number of bedrooms'\n",
    "    print(\"\\n\\nThe highest price of a property per number of bedrooms:\\n\\n\")\n",
    "    print(max_price_bed)\n",
    "    \n",
    "    return max_price_bed\n",
    "\n",
    "def question_four(data):\n",
    "    pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "    sum_price_bed = data[['price','bedrooms']].groupby('bedrooms').sum()\n",
    "    sum_price_bed.rename(columns={'price':'Sum of prices'}, inplace=True)\n",
    "    sum_price_bed.index.name = 'Number of bedrooms'\n",
    "    print(\"\\n\\nThe sum of the prices per number of bedrooms:\\n\\n\")\n",
    "    print(sum_price_bed)\n",
    "    \n",
    "    return sum_price_bed\n",
    "\n",
    "def question_five(data):\n",
    "    bed_bath = data[['price','bedrooms','bathrooms']].groupby(['bedrooms','bathrooms']).sum()\n",
    "    bed_bath.rename(columns={'price':'Sum of prices'}, inplace=True)\n",
    "    print(\"\\n\\nThe sum of the prices per number of bedrooms and bathrooms:\\n\\n\")\n",
    "    print(bed_bath)\n",
    "    \n",
    "    return bed_bath\n",
    "\n",
    "def question_six(dataset):\n",
    "    mean_liv = dataset[['sqft_living','yr_built']].groupby('yr_built').mean()\n",
    "    mean_liv.rename(columns={'sqft_living': \"Living room average area\"}, inplace=True)\n",
    "    mean_liv.index.name = \"Construction year\"\n",
    "    print(\"\\n\\nLiving room average area per construction year:\\n\\n\")\n",
    "    print(mean_liv)\n",
    "    \n",
    "    return mean_liv\n",
    "\n",
    "def question_seven(dataset):\n",
    "    median_liv = dataset[['sqft_living','yr_built']].groupby('yr_built').median()\n",
    "    median_liv.rename(columns={'sqft_living': \"Living room median area\"}, inplace=True)\n",
    "    median_liv.index.name = \"Construction year\"\n",
    "    print(\"\\n\\nLiving room median area per construction year:\\n\\n\")\n",
    "    print(median_liv)\n",
    "    \n",
    "    return median_liv\n",
    "\n",
    "def question_eight(dataset):\n",
    "    std_liv = dataset[['sqft_living','yr_built']].groupby('yr_built').std()\n",
    "    std_liv.rename(columns={'sqft_living': \"Living room standard deviation\"}, inplace=True)\n",
    "    std_liv.index.name = \"Construction year\"\n",
    "    print(\"\\n\\nLiving room standard deviation per construction year:\\n\\n\")\n",
    "    print(std_liv)\n",
    "    \n",
    "    return std_liv\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    per_yr = question_one(dataset)\n",
    "    \n",
    "    min_bed_yr = question_two(dataset)\n",
    "    \n",
    "    max_price_bed = question_three(data)\n",
    "    \n",
    "    sum_price_bed = question_four(data)\n",
    "    \n",
    "    bed_bath = question_five(data)\n",
    "    \n",
    "    mean_liv = question_six(dataset)\n",
    "    \n",
    "    median_liv = question_seven(dataset)\n",
    "    \n",
    "    std_liv = question_eight(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daff1f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bf4c61d",
   "metadata": {},
   "source": [
    "### 2.1.5. Q&R 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ae3460",
   "metadata": {},
   "source": [
    "1. Create a column called: dormitory_type.\n",
    "   - If the value of the column \"bedrooms\" is equal to 1 => 'studio'.\n",
    "   - If the value of the column \"bedrooms\" is equal to 2 => 'apartment'.\n",
    "   - If the value of the column \"bedrooms\" is greater than 2 => 'house'.\n",
    "2. Draw a bar chart: sum of the prices per number of bedrooms.\n",
    "3. Draw a line chart: average price per year of construction.\n",
    "4. Draw a bar chart: average price per dormitory type.\n",
    "5. Draw a line chart: price per year of renovation - since 1930.\n",
    "6. Make a table: average price per year of construction and per dormitory type.\n",
    "7. Create a dashboard with the charts of the questions 02, 03 and 04.\n",
    "8. Create a dashboard with the charts of the questions 02 and 04.\n",
    "9. Create a dashboard with the charts of the questions 03 and 05.\n",
    "10. Create a map with the points proportional to to the living room size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e95a98e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b45650ef",
   "metadata": {},
   "source": [
    "### 2.1.6. Q&R 6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d9ceb7",
   "metadata": {},
   "source": [
    "1. How many properties per level?\n",
    "   - Level 0: price between 0.00 and 321.950\n",
    "   - Level 1: price between 321.950 and 450.000\n",
    "   - Level 2: price between 450.000 and 645.000\n",
    "   - Level 3: price above 645.000\n",
    "2. Add the following information to the properties:\n",
    "   - Street;\n",
    "   - Number;\n",
    "   - Neighbourhood;\n",
    "   - City;\n",
    "   - State.\n",
    "3. Add the level of the price as a color in the map.\n",
    "4. Make the points proportional to the price in the map.\n",
    "5. Add filters to the map:\n",
    "   - Water view or not;\n",
    "   - Value of the price.\n",
    "6. Add a filter to the last dashboard:\n",
    "   - Show values only from a specific date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e87d31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da4a6f15",
   "metadata": {},
   "source": [
    "### 2.1.7. Q&R 7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f464affb",
   "metadata": {},
   "source": [
    "Deploy to Heroku a portfolio as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcad61d7",
   "metadata": {},
   "source": [
    "1. Add filters by region.\n",
    "2. Choose attributes to visualize.\n",
    "3. Total number of properties by zipcode, average by zipcode, average living room size by zipcode and average price per square meters by zipcode. \n",
    "4. Descriptive analysis for each column.\n",
    "5. Daily and annual price fluctuation.\n",
    "6. Properties distributed by: price, number of bedrooms, number of bathrooms, number of floors and waterfront."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ace47b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30591ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
